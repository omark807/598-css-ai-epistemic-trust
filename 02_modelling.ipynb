{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import reduce, partial\n",
        "# import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "%pip install torch\n",
        "# faiss is not supported on macOS with CUDA, so you can remove it if it's not needed.\n",
        "# import faiss\n",
        "# from faiss.contrib.ondisk import merge_ondisk\n",
        "import os, re, glob\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from collections import namedtuple\n",
        "import pickle as pkl\n",
        "from datetime import timezone, datetime, timedelta\n",
        "import pytz\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from tqdm.contrib import tenumerate\n",
        "\n",
        "# Replaced cuml imports (CUDA-based) with sklearn and other alternatives\n",
        "from sklearn.ensemble import RandomForestClassifier as rfc  # CPU-based Random Forest\n",
        "from sklearn.svm import SVC  # CPU-based Support Vector Machine\n",
        "from sklearn.linear_model import LogisticRegression  # CPU-based Logistic Regression\n",
        "\n",
        "from sklearn.metrics import accuracy_score  # Replaced cuml.metrics with sklearn.metrics for CPU support\n",
        "\n",
        "from xgboost import XGBClassifier  # xgboost is CPU-based by default, you don't need a GPU version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (3.3.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from sentence-transformers) (4.67.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRXuAfhWUDGL"
      },
      "source": [
        "Add empty folders 'processed', 'embeddings', 'index'\n",
        "\n",
        "Put all pre-processed .csv files in the 'processed' folder. the files need to have a column named 'sentence'.\n",
        "\n",
        "Upload models-2023-04-10-2229.pkl and trained.index\n",
        "run the code below to install relevant dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jOKgTyGDT4QY"
      },
      "outputs": [],
      "source": [
        "def sorted_alphanumeric(data):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
        "    return sorted(data, key=alphanum_key)\n",
        "def files(dir):\n",
        "  return sorted_alphanumeric([dir + x for x in os.listdir(dir)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW52obJUUa0_",
        "outputId": "4889daae-e8da-41a4-ab86-0f30cf76a4ab"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('msmarco-distilbert-base-v4') # asymmetric\n",
        "\n",
        "taxonomy = {\n",
        "    \"competence\": {\n",
        "        \"competence_trust\": [\"intelligent\", \"reasoned\", \"informed\", \"evidence\", \"accurate\", \"truthful\"],\n",
        "        \"competence_distrust\": [\"stupid\", \"incompetent\", \"ignorant\", \"idiot\", \"sheep\", \"insane\", \"moron\",\n",
        "                                \"dumbass\", \"clown\", \"living in your bubble\", \"incoherent\", \"nonsense\", \"no proof\",\n",
        "                                \"accept reality\", \"irrational\", \"retarded\", \"intellectually dishonest\",\n",
        "                                \"misleading\", \"indoctrinated\"] # new\n",
        "    },\n",
        "    \"sincerity\": {\n",
        "        \"sincerity_trust\": [\"trustworthy\", \"reputable\", \"sincere\", \"genuine\"],\n",
        "        \"sincerity_distrust\": [\"liar\", \"dishonest\", \"untrustworthy\", \"corrupt\", \"inhuman\", \"immoral\",\n",
        "                               \"disinformation\", \"misinformation\", \"propaganda\", \"fake news\", \"unreliable source\", \"paranoid\", \"shill\",\n",
        "                               \"bias\", \"discredited\", \"manipulated\", \"scam\"] # new\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Uw0GA09LUdT1"
      },
      "outputs": [],
      "source": [
        "def flatten_taxonomy(taxonomy, keys=[]):\n",
        "  if type(taxonomy) is not dict:\n",
        "    return [(x, keys) for x in taxonomy]\n",
        "  return reduce(lambda x, y: x + y, [flatten_taxonomy(t, keys + [k]) for k, t in taxonomy.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FN2dh0WhUglj"
      },
      "outputs": [],
      "source": [
        "def t2i_i2t_embeddings(flat_taxonomy, model):\n",
        "  t2i = {k: i for i, (k, v) in enumerate(flat_taxonomy)}\n",
        "  i2t = {i: k for i, (k, v) in enumerate(flat_taxonomy)}\n",
        "  embs = model.encode([i2t[i] for i in range(len(flat_taxonomy))], normalize_embeddings=True)\n",
        "  return (t2i, i2t, embs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LvH2QmRUkrd",
        "outputId": "cb5f80a2-6ebe-4679-dd94-9a27d8670d8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(46, 768)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_taxonomy = flatten_taxonomy(taxonomy)\n",
        "t2i, i2t, taxonomy_embs = t2i_i2t_embeddings(flat_taxonomy, model)\n",
        "taxonomy_embs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxMXWbYFUoCF"
      },
      "source": [
        "flat_taxonomy -->\n",
        "\n",
        "[('intelligent', ['competence', 'competence_trust']),\n",
        "\n",
        " ('reasoned', ['competence', 'competence_trust']),\n",
        "\n",
        " ('informed', ['competence', 'competence_trust']),..]\n",
        "\n",
        "t2i -->\n",
        "\n",
        "{'intelligent': 0,\n",
        "\n",
        " 'reasoned': 1,\n",
        "\n",
        " 'informed': 2,\n",
        "\n",
        " 'evidence': 3,...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qEHTyLvYUny-"
      },
      "outputs": [],
      "source": [
        "## You don't need the below code -- I provide a trained index file. But here it is for reference!\n",
        "## Embed a sample of sentences and train index\n",
        "# embeddings = model.encode(sentences_sample, batch_size=128, normalize_embeddings=True)\n",
        "\n",
        "# index = faiss.index_factory(768, \"OPQ64_256,IVF262144_HNSW32,PQ64\") # train on embeddings...\n",
        "\n",
        "# index_ivf = faiss.extract_index_ivf(index)\n",
        "# clustering_index = faiss.index_cpu_to_all_gpus(faiss.IndexFlatL2(index_ivf.d))\n",
        "# index_ivf.clustering_index = clustering_index\n",
        "\n",
        "# index.train(embeddings) # training on GPU -- 42 mins vs > 5hrs!!\n",
        "# index_ivf.clustering_index = faiss.index_gpu_to_cpu(index_ivf.clustering_index)\n",
        "# faiss.write_index(index, \"trained.index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1DRMi2EUUlT0"
      },
      "outputs": [],
      "source": [
        "csvs = files(\"processed/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGv7ELZgU6to",
        "outputId": "227d4f23-0153-4982-d0fc-a83d25312387"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "argument of type 'ellipsis' is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, csv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(csvs):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.ipynb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m csv:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# Read CSV file\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'ellipsis' is not iterable"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Assuming 'taxonomy_embs' is already loaded or defined\n",
        "taxonomy_embs = ...  # Load or define your taxonomy embeddings here\n",
        "\n",
        "offset_total = 0\n",
        "csvs = [...]  # List of CSV files to process\n",
        "\n",
        "# Initialize SentenceTransformer model (if not already initialized)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "for i, csv in enumerate(csvs):\n",
        "    if '.ipynb' not in csv:\n",
        "        print(f\"Processing {csv}\")\n",
        "        \n",
        "        # Read CSV file\n",
        "        df = pd.read_csv(csv)\n",
        "        sents = [str(x) for x in df[\"sentence\"]]\n",
        "        \n",
        "        # Encode the sentences to embeddings\n",
        "        embs = model.encode(sents, normalize_embeddings=True)\n",
        "        \n",
        "        # Compute cosine similarity between the taxonomy and sentence embeddings\n",
        "        sims = cosine_similarity(taxonomy_embs, embs)\n",
        "        \n",
        "        # Save the similarities to a pickle file\n",
        "        with open(f\"embeddings/embs-{os.path.basename(csv)}.pkl\", \"wb\") as f:\n",
        "            pkl.dump(sims, f)\n",
        "\n",
        "        # Simulating a local storage of embeddings (instead of using faiss index)\n",
        "        # For simplicity, we will use numpy arrays to store the embeddings\n",
        "        \n",
        "        print(f\"Writing embeddings for block_{os.path.basename(csv)}.npy...\")\n",
        "        \n",
        "        # Save the embeddings to a file (using NumPy)\n",
        "        np.save(f\"embeddings/block_{os.path.basename(csv)}.npy\", embs)\n",
        "\n",
        "        # Simulate a simple index by just saving the embeddings\n",
        "        print(f\"Index for block_{os.path.basename(csv)}.index...\")\n",
        "        with open(f\"index/block_{os.path.basename(csv)}.index\", \"wb\") as f:\n",
        "            pkl.dump(embs, f)\n",
        "        \n",
        "        # Update the offset for next batch of embeddings\n",
        "        offset_total += len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHjV2DrCU7av"
      },
      "outputs": [],
      "source": [
        "## Running models\n",
        "\n",
        "def construct_data(prompts, sims, t2i, threshold=0.5, neg_to_pos_ratio=1):\n",
        "  sent_emb_idx_positive = set()\n",
        "  sent_emb_idx_negative = set()\n",
        "  #sims = util.cos_sim(model.encode(prompts, normalize_embeddings=True), sentence_embeddings)\n",
        "  sims = sims[[t2i[x] for x in prompts]] # keeps row logic working below\n",
        "  for i, prompt in enumerate(prompts):\n",
        "    #sorted_idxs = torch.argsort(-sims[i])\n",
        "    pos_idxs = torch.argwhere(sims[i] >= threshold).flatten().tolist()\n",
        "    neg_idxs = torch.argwhere(sims[i] < threshold).flatten().tolist()\n",
        "    pos = set(pos_idxs)\n",
        "    neg = set(np.random.choice(neg_idxs, round(len(pos) * neg_to_pos_ratio)))\n",
        "    sent_emb_idx_positive = sent_emb_idx_positive.union(pos)\n",
        "    sent_emb_idx_negative = sent_emb_idx_negative.union(neg)\n",
        "  return {\"positive\": list(sent_emb_idx_positive), \"negative\": list(sent_emb_idx_negative)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I33XvAgTU_3o"
      },
      "outputs": [],
      "source": [
        "def expand_data(data, df, model, index, nprobe=2048, k=3, expand=True):\n",
        "  if not expand:\n",
        "    return []\n",
        "  query_embs = model.encode(df.iloc[data[\"positive\"]][\"sentence\"].tolist(), normalize_embeddings=True) #embeddings[data[\"positive\"]]\n",
        "  index.nprobe = nprobe\n",
        "  D, I = index.search(query_embs, k)\n",
        "  new_sents = I.flatten().tolist()\n",
        "  print(f\"Expanded {query_embs.shape[0]} examples by {len(new_sents)} to {query_embs.shape[0] + len(new_sents)}\")\n",
        "  return new_sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBGOu7YLVCc_"
      },
      "outputs": [],
      "source": [
        "# Use the pretrained index...\n",
        "index = faiss.read_index(\"trained.index\")\n",
        "blocks = files(\"index/\")\n",
        "merge_ondisk(index, blocks, \"merged_index.ivfdata\")\n",
        "faiss.write_index(index, \"populated.index\")\n",
        "#index.ntotal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6a80412571ff4744ae7a4bc9b7aca2f1",
            "f05b1fc030d4487a9c71077f929de7da",
            "28b7587daaa74705aeb58606f68b7f24",
            "9b6a2db940c5498c86e57f785fad5639",
            "52f10ea83f0c495ba046cee3e21bb22e",
            "7d6726ccd25d4881be6df83e71e59e6e",
            "73cf1644e96f43ff959a4a2ef4090855",
            "92016b19965b41c9813977a4c72dd4a9",
            "35cf618647a84376bee4297eb2e3676f",
            "d7254f403e4f427b85561d95a9b91d6c",
            "168c5cfbe8fc48fba3cef2575ffc7c95",
            "b32956548061471da33405561bd29289",
            "961843a7edae4dbaae6f38e5ab218ffd",
            "ff0956f44f5546af8e4413f98d5e1202",
            "7aa31577d9844ecda5b1499ef9a5960a",
            "99e9cea04294423e98b2a17d182284e7",
            "feaa9fda9579415399c326e7573f161c",
            "100a0a145b2a4d498784acecf965e297",
            "212bae3b2bda44eb8b910d800ffb15ab",
            "0009d3cbd62b47d1a7dd5ad29f621770",
            "e47218a67935437d9c66bab1f5061c63",
            "af78be4d1ae94450b63faa546c2fbed8"
          ]
        },
        "id": "CQTmJUo_VEq-",
        "outputId": "3a05ce97-74e5-4560-9429-afae030bcfab"
      },
      "outputs": [],
      "source": [
        "# Construct and expand data\n",
        "eptrust_categories = [\"competence_distrust\", \"competence_trust\", \"sincerity_distrust\", \"sincerity_trust\"]\n",
        "mdl_data = {category: {\"pos\": [], \"neg\": [], \"pos_sims\": [], \"neg_sims\": [], \"pos_nn\": []} for category in eptrust_categories}\n",
        "\n",
        "csvs = files(\"processed/\")\n",
        "\n",
        "for csv in tqdm(csvs):\n",
        "  print(f\"##### Processing {csv}...\")\n",
        "  df = pd.read_csv(csv)\n",
        "  with open(f\"embeddings/embs-{os.path.basename(csv)}.pkl\", \"rb\") as f:\n",
        "    sims = pkl.load(f)\n",
        "\n",
        "  for category in eptrust_categories:\n",
        "    print(f\"# Processing {category}...\")\n",
        "    qry = [x for x, y in flat_taxonomy if category in y]\n",
        "    data = construct_data(qry, sims, t2i, neg_to_pos_ratio=20) # df.iloc[x[\"positive\"]]\n",
        "    pos_expand = expand_data(data, df, model, index, nprobe=2048, k=5, expand=True)\n",
        "\n",
        "    mdl_data[category][\"pos\"].append(df.iloc[data[\"positive\"]])\n",
        "    mdl_data[category][\"neg\"].append(df.iloc[data[\"negative\"]])\n",
        "    mdl_data[category][\"pos_sims\"].append(sims[:, data[\"positive\"]])\n",
        "    mdl_data[category][\"neg_sims\"].append(sims[:, data[\"negative\"]])\n",
        "    mdl_data[category][\"pos_nn\"].append(pos_expand)\n",
        "\n",
        "\n",
        "mdl_nn_data = {category: {\"pos_nn_index\": {}, \"pos_nn_data\": []} for category in eptrust_categories}\n",
        "n_per_file = 100000\n",
        "\n",
        "for category in eptrust_categories:\n",
        "  pos_nn = set(reduce(lambda x, y: x + y, mdl_data[category][\"pos_nn\"]))\n",
        "  pos_nn_index = {}\n",
        "\n",
        "  for x in pos_nn:\n",
        "    if (x // n_per_file) not in pos_nn_index:\n",
        "      pos_nn_index[x // n_per_file] = []\n",
        "    pos_nn_index[x // n_per_file].append(x % n_per_file)\n",
        "  mdl_nn_data[category][\"pos_nn_index\"] = pos_nn_index\n",
        "#print(pos_nn_index)\n",
        "for file_id, csv in tenumerate(csvs):\n",
        "  for category in eptrust_categories:\n",
        "    df = pd.read_csv(csv)\n",
        "    if file_id not in pos_nn_index:\n",
        "      print(f\"Nothing in {csv}... weird.\")\n",
        "    else:\n",
        "      pos_nn_index = mdl_nn_data[category][\"pos_nn_index\"]\n",
        "      #print(pos_nn_index)\n",
        "      #print(file_id)\n",
        "      #### NOTE: this is probably due to trained.index using 1000000-sized chunks and our.index files using 100000-sized chunks.\n",
        "      #### Contact Dominic for details on trianing our own train.index/getting more RAM space to use larger chunk sizes.\n",
        "      valid_indices = [i for i in pos_nn_index[file_id] if 0 <= i < len(df)]\n",
        "      if valid_indices:\n",
        "        mdl_nn_data[category][\"pos_nn_data\"].append(df.iloc[valid_indices])\n",
        "      else:\n",
        "        print(f\"No valid indices found for file {file_id} in category {category}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO4KJ7dIVIkX"
      },
      "outputs": [],
      "source": [
        "# Now to collate the data and train models\n",
        "def prepare_data(category, mdl_data, mdl_nn_data, model, taxonomy_embs, i2t, raw=False):\n",
        "  print(f\"Preparing {category}...\")\n",
        "  pos_mat = torch.concat(mdl_data[category][\"pos_sims\"], dim=1)\n",
        "  pos_data = pd.DataFrame(pos_mat.numpy()).rename(i2t).transpose()\n",
        "\n",
        "  neg_mat = torch.concat(mdl_data[category][\"neg_sims\"], dim=1)\n",
        "  neg_data = pd.DataFrame(neg_mat.numpy()).rename(i2t).transpose()\n",
        "\n",
        "  df_expanded = pd.concat(mdl_nn_data[category][\"pos_nn_data\"])\n",
        "  pos_nn_embs = model.encode(df_expanded[\"sentence\"].tolist(), normalize_embeddings=True)\n",
        "  pos_nn_mat = util.cos_sim(taxonomy_embs, pos_nn_embs)\n",
        "  pos_nn_data = pd.DataFrame(pos_nn_mat.numpy()).rename(i2t).transpose()\n",
        "  print(f\"Positive: {pos_mat.shape}, Negative: {neg_mat.shape}, Expanded: {pos_nn_mat.shape}\")\n",
        "  pos_data = pd.concat([pos_data, pos_nn_data])\n",
        "\n",
        "  if raw:\n",
        "    pos_mat = model.encode(pd.concat(mdl_data[category][\"pos\"])[\"sentence\"].tolist(), normalize_embeddings=True)\n",
        "    neg_mat = model.encode(pd.concat(mdl_data[category][\"neg\"])[\"sentence\"].tolist(), normalize_embeddings=True)\n",
        "    pos_data = pd.concat([pd.DataFrame(pos_mat), pd.DataFrame(pos_nn_embs)])\n",
        "    neg_data = pd.DataFrame(neg_mat)\n",
        "    print(f\"Positive: {pos_mat.shape}, Negative: {neg_mat.shape}, Expanded: {pos_nn_embs.shape}\")\n",
        "\n",
        "  pos_data[\"label\"] = 1\n",
        "  neg_data[\"label\"] = 0\n",
        "  data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thM4L362VL1w"
      },
      "outputs": [],
      "source": [
        "def run_mdl(data, rf_max_depth=5, test=0.3):\n",
        "  y_data = data[\"label\"]\n",
        "  x_data = data.drop(\"label\", axis = 1)\n",
        "  x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x_data, y_data, test_size = test)\n",
        "\n",
        "  #lm = LogisticRegression(penalty=\"none\", solver=\"saga\", max_iter=1000), MLPClassifier(random_state=1, hidden_layer_sizes=(384, 192, 96))\n",
        "  mdl = curfc(max_depth=rf_max_depth) # this one standard\n",
        "  #mdl = MLPClassifier(random_state=1, hidden_layer_sizes=(24, 12, 6))\n",
        "  #mdl = XGBClassifier(n_estimators=4, max_depth=rf_max_depth, learning_rate=1, objective='binary:logistic')\n",
        "  mdl.fit(x_training_data, y_training_data)\n",
        "  predictions = mdl.predict(x_test_data)\n",
        "  print(classification_report(y_test_data, predictions))\n",
        "  return mdl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwmXEzNfVOVs"
      },
      "outputs": [],
      "source": [
        "def run_mdl_full(data, estimator):\n",
        "  y_data = data[\"label\"]\n",
        "  x_data = data.drop(\"label\", axis = 1)\n",
        "\n",
        "  mdl = estimator(None)\n",
        "  mdl.fit(x_data, y_data)\n",
        "  return mdl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsXOonbEVV6H"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "estimators = {\n",
        "    \"RF\": lambda x: RandomForestClassifier(max_depth=10, random_state=1),  # Replaced curfc with sklearn's RandomForestClassifier\n",
        "    \"MLP\": lambda x: MLPClassifier(random_state=1, hidden_layer_sizes=(24, 12, 6)),\n",
        "    \"XGB\": lambda x: XGBClassifier(n_estimators=4, max_depth=10, learning_rate=1, objective='binary:logistic'),\n",
        "    \"LR\": lambda x: LogisticRegression(),\n",
        "    \"SVM\": lambda x: SVC(kernel='rbf', degree=3, gamma='auto', C=1)  # Uncommented and included the SVM model\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FpfOiifVYVl"
      },
      "outputs": [],
      "source": [
        "def write_sentence_data(mdl_data, mdl_nn_data, category, outfile):\n",
        "  pos = pd.concat(mdl_data[category][\"pos\"] + mdl_nn_data[category][\"pos_nn_data\"])\n",
        "  neg = pd.concat(mdl_data[category][\"neg\"])\n",
        "  pos[\"label\"] = 1\n",
        "  neg[\"label\"] = 0\n",
        "  print(f\"Positive: {pos.shape}, Negative: {neg.shape}, outfile: {outfile}\")\n",
        "  pd.concat([pos, neg]).to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCsv8EVlVadt",
        "outputId": "2178e857-c90d-49ed-de7f-794e4f44fbd7"
      },
      "outputs": [],
      "source": [
        "write_sentence_data(mdl_data, mdl_nn_data, \"competence_distrust\", \"competence_distrust_data.csv\")\n",
        "write_sentence_data(mdl_data, mdl_nn_data, \"sincerity_distrust\", \"sincerity_distrust_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXjAuaUOVdwd",
        "outputId": "9cc579ee-66e7-4dba-a068-d9dc3058ff31"
      },
      "outputs": [],
      "source": [
        "# Finally!\n",
        "prepped_data = {category: prepare_data(category, mdl_data, mdl_nn_data, model, taxonomy_embs, i2t, raw=False) for category in eptrust_categories}\n",
        "mdls = {\n",
        "    est_name: {\n",
        "        cat: run_mdl_full(df, estimator) for cat, df in prepped_data.items()\n",
        "    } for est_name, estimator in estimators.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6okL6cfVio6"
      },
      "outputs": [],
      "source": [
        "def cls_(sents, mdls, model, taxonomy_embs, i2t, raw=False, sims=None):\n",
        "  if sims is None:\n",
        "    embs = model.encode(sents, normalize_embeddings=True)\n",
        "    test_data = pd.DataFrame(util.cos_sim(taxonomy_embs, embs).numpy()).rename(i2t).transpose()\n",
        "  else:\n",
        "    test_data = pd.DataFrame(sims.numpy()).rename(i2t).transpose()\n",
        "  if raw:\n",
        "    test_data = pd.DataFrame(embs)\n",
        "  df_res = pd.concat([mdl.predict_proba(test_data)[1].rename(cat) for cat, mdl in mdls.items()], axis=1) # RFs\n",
        "  #df_res = pd.concat([pd.Series(mdl.predict_proba(test_data)[:,1]).rename(cat) for cat, mdl in mdls.items()], axis=1) # almost everything else lol\n",
        "  return df_res.rename(index={i: s for i, s in enumerate(sents)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "ak1xOczuVlx7",
        "outputId": "d9fa60ac-ecf9-4619-e322-ea04b9ac6cf3"
      },
      "outputs": [],
      "source": [
        "cls = partial(cls_, mdls=mdls[\"RF\"], model=model, taxonomy_embs=taxonomy_embs, i2t=i2t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omECeatRVoMb"
      },
      "outputs": [],
      "source": [
        "# Example table in the paper\n",
        "sents = [\"you are ignorant and a liar\", \"democrats are idiots\", \"democrats are liars\", \"republicans are dumb\", \"you're smart\", \"democrats are intelligent, trustworthy\", \"Alice is trustworthy, but Bob is stupid.\"]\n",
        "res = cls(sents)\n",
        "res.round(4)\n",
        "\n",
        "threshold = 0.5\n",
        "res.mask(res > threshold, \"*\").mask(res <= threshold, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sx6Ff8oVsDg"
      },
      "outputs": [],
      "source": [
        "# Readout models\n",
        "fname = \"models-\" + datetime.today().astimezone(pytz.timezone('US/Central')).strftime('%Y-%m-%d-%H%M') + \".pkl\"\n",
        "with open(fname, \"wb\") as f:\n",
        "  pkl.dump(mdls, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZbYLShKVxvT"
      },
      "outputs": [],
      "source": [
        "# Running the models on your own data, assuming it's a dataframe with a \"sentence\" column (feel free to precompute with the \"sims\" arg):\n",
        "cls(sents=df[\"sentence\"].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhsCOlt2Fn8f",
        "outputId": "c6a98502-b028-4a46-9aec-e859ee61f5c2"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/models-2023-04-10-2229.pkl', 'rb') as file:\n",
        "    d_mdls = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYUIGilwHJ3R"
      },
      "outputs": [],
      "source": [
        "df_before = pd.read_csv('/content/processed/before_april_chunck_0.csv')\n",
        "df_after = pd.read_csv('/content/processed/after_april_chunck_0.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFJIaTyvPehI",
        "outputId": "f3cd11b4-2849-4dcc-d6f7-19f1cde91410"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade treelite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "collapsed": true,
        "id": "wFAFVw8hGUUN",
        "outputId": "332806d5-c1b7-401a-e101-6cd5941beddd"
      },
      "outputs": [],
      "source": [
        "cls2 = partial(cls_, mdls=d_mdls[\"RF\"], model=model, taxonomy_embs=taxonomy_embs, i2t=i2t)\n",
        "result_before = cls2(sents=df_before[\"sentence\"].tolist())\n",
        "result_before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHNgS643PZ3h"
      },
      "outputs": [],
      "source": [
        "sents = [\"you are ignorant and a liar\", \"democrats are idiots\", \"democrats are liars\", \"republicans are dumb\", \"you're smart\", \"democrats are intelligent, trustworthy\", \"Alice is trustworthy, but Bob is stupid.\"]\n",
        "res = cls2(sents)\n",
        "res.round(4)\n",
        "\n",
        "threshold = 0.5\n",
        "res.mask(res > threshold, \"*\").mask(res <= threshold, \"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0009d3cbd62b47d1a7dd5ad29f621770": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "100a0a145b2a4d498784acecf965e297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "168c5cfbe8fc48fba3cef2575ffc7c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "212bae3b2bda44eb8b910d800ffb15ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b7587daaa74705aeb58606f68b7f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92016b19965b41c9813977a4c72dd4a9",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35cf618647a84376bee4297eb2e3676f",
            "value": 19
          }
        },
        "35cf618647a84376bee4297eb2e3676f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52f10ea83f0c495ba046cee3e21bb22e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a80412571ff4744ae7a4bc9b7aca2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f05b1fc030d4487a9c71077f929de7da",
              "IPY_MODEL_28b7587daaa74705aeb58606f68b7f24",
              "IPY_MODEL_9b6a2db940c5498c86e57f785fad5639"
            ],
            "layout": "IPY_MODEL_52f10ea83f0c495ba046cee3e21bb22e"
          }
        },
        "73cf1644e96f43ff959a4a2ef4090855": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aa31577d9844ecda5b1499ef9a5960a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e47218a67935437d9c66bab1f5061c63",
            "placeholder": "​",
            "style": "IPY_MODEL_af78be4d1ae94450b63faa546c2fbed8",
            "value": " 19/19 [00:11&lt;00:00,  2.05it/s]"
          }
        },
        "7d6726ccd25d4881be6df83e71e59e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92016b19965b41c9813977a4c72dd4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961843a7edae4dbaae6f38e5ab218ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feaa9fda9579415399c326e7573f161c",
            "placeholder": "​",
            "style": "IPY_MODEL_100a0a145b2a4d498784acecf965e297",
            "value": "100%"
          }
        },
        "99e9cea04294423e98b2a17d182284e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b6a2db940c5498c86e57f785fad5639": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7254f403e4f427b85561d95a9b91d6c",
            "placeholder": "​",
            "style": "IPY_MODEL_168c5cfbe8fc48fba3cef2575ffc7c95",
            "value": " 19/19 [00:29&lt;00:00,  1.04s/it]"
          }
        },
        "af78be4d1ae94450b63faa546c2fbed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b32956548061471da33405561bd29289": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_961843a7edae4dbaae6f38e5ab218ffd",
              "IPY_MODEL_ff0956f44f5546af8e4413f98d5e1202",
              "IPY_MODEL_7aa31577d9844ecda5b1499ef9a5960a"
            ],
            "layout": "IPY_MODEL_99e9cea04294423e98b2a17d182284e7"
          }
        },
        "d7254f403e4f427b85561d95a9b91d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47218a67935437d9c66bab1f5061c63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f05b1fc030d4487a9c71077f929de7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d6726ccd25d4881be6df83e71e59e6e",
            "placeholder": "​",
            "style": "IPY_MODEL_73cf1644e96f43ff959a4a2ef4090855",
            "value": "100%"
          }
        },
        "feaa9fda9579415399c326e7573f161c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0956f44f5546af8e4413f98d5e1202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212bae3b2bda44eb8b910d800ffb15ab",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0009d3cbd62b47d1a7dd5ad29f621770",
            "value": 19
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
